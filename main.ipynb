{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essensial Imports\n",
    "* using os to access files\n",
    "* using pandas to read csv data files\n",
    "* using tensorflow framework for normalizing and data cleaning\n",
    "* using tensorBoard to visualize learing process\n",
    "* using numpy to convert arrays to numpy arrays\n",
    "* using hazm for Farsi text normalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from hazm import Normalizer, sent_tokenize, word_tokenize, Stemmer\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow version check\n",
    "* Latest available version for tensorflow at the moment is 1.13.1, But for NLP we should\n",
    "use 2.x. So using `enable_eager_execution()` to perform functions as 2.x\n",
    "\n",
    "**Note**: If you are using 2.x tensorflow, you dont need this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1858808684693237231\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 18013350971989020986\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11015042985065621008\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3076849664\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10039970566583395186\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data from csv files\n",
    "* we use `pd.read_csv()` to read training and test files and `pd.dropna()` to drop\n",
    "not available records.\n",
    "* we use `df.sample()` to shuffle dataframes rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                     130000\n",
      "title                  130000\n",
      "comment                130000\n",
      "rate                   130000\n",
      "verification_status    130000\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>rate</th>\n",
       "      <th>verification_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78116</th>\n",
       "      <td>86900</td>\n",
       "      <td>معیوب</td>\n",
       "      <td>علی رغم اینکه بسته بندی کالا خوب به نظر می رسی...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119968</th>\n",
       "      <td>133413</td>\n",
       "      <td>پوست من روشنه و این ضدآفتاب بسیار مناسب پوست‌ه...</td>\n",
       "      <td>پیشنهاد میکنم برای پوستهای روشن</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46107</th>\n",
       "      <td>51367</td>\n",
       "      <td>کارآمد و مناسب</td>\n",
       "      <td>کارآمد و مناسب</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3343</th>\n",
       "      <td>3752</td>\n",
       "      <td>خوشبو</td>\n",
       "      <td>واقعا خوشبو هست فقط ماندگاری نداره قیمتشم خوبه</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25524</th>\n",
       "      <td>28424</td>\n",
       "      <td>فوق العاده زیبا و جذاب ولی قیمت بالا</td>\n",
       "      <td>من این لپ تاپ را در حدود سه روز هست که تحویل گ...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "78116    86900                                              معیوب   \n",
       "119968  133413  پوست من روشنه و این ضدآفتاب بسیار مناسب پوست‌ه...   \n",
       "46107    51367                                     کارآمد و مناسب   \n",
       "3343      3752                                              خوشبو   \n",
       "25524    28424               فوق العاده زیبا و جذاب ولی قیمت بالا   \n",
       "\n",
       "                                                  comment  rate  \\\n",
       "78116   علی رغم اینکه بسته بندی کالا خوب به نظر می رسی...  60.0   \n",
       "119968                    پیشنهاد میکنم برای پوستهای روشن   0.0   \n",
       "46107                                      کارآمد و مناسب   0.0   \n",
       "3343       واقعا خوشبو هست فقط ماندگاری نداره قیمتشم خوبه  52.0   \n",
       "25524   من این لپ تاپ را در حدود سه روز هست که تحویل گ...  94.0   \n",
       "\n",
       "        verification_status  \n",
       "78116                     0  \n",
       "119968                    0  \n",
       "46107                     0  \n",
       "3343                      0  \n",
       "25524                     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./datasets/train_comments.csv').dropna()\n",
    "\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "num_training_samples = 130000\n",
    "\n",
    "training_data = data.iloc[:num_training_samples]\n",
    "testing_data = data.iloc[num_training_samples:]\n",
    "\n",
    "print(training_data.count())\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                     27564\n",
      "title                  27564\n",
      "comment                27564\n",
      "rate                   27564\n",
      "verification_status    27564\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>rate</th>\n",
       "      <th>verification_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134230</th>\n",
       "      <td>149172</td>\n",
       "      <td>افتضاحه</td>\n",
       "      <td>قیچیش تا میشه اصلا کارکرد قیچی رو نداره یه ماک...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142564</th>\n",
       "      <td>158431</td>\n",
       "      <td>مناسب نیست</td>\n",
       "      <td>خوب نیست همش جدا میشه از گوشی</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61750</th>\n",
       "      <td>68728</td>\n",
       "      <td>درجه بندی</td>\n",
       "      <td>بعداز یه مدت درجه بندیش پاک میشه و قابل استفاد...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57936</th>\n",
       "      <td>64533</td>\n",
       "      <td>عالیه</td>\n",
       "      <td>یک روزه دستم رسید عالیه ممنونم از دیجی کالا وا...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146577</th>\n",
       "      <td>162904</td>\n",
       "      <td>وسیله سرگرمی خوبیه</td>\n",
       "      <td>به عنوان هدیه گرفتم عالیه طرحش جنسش وقتی بسترو...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id               title  \\\n",
       "134230  149172             افتضاحه   \n",
       "142564  158431          مناسب نیست   \n",
       "61750    68728           درجه بندی   \n",
       "57936    64533               عالیه   \n",
       "146577  162904  وسیله سرگرمی خوبیه   \n",
       "\n",
       "                                                  comment  rate  \\\n",
       "134230  قیچیش تا میشه اصلا کارکرد قیچی رو نداره یه ماک...   8.0   \n",
       "142564                      خوب نیست همش جدا میشه از گوشی  60.0   \n",
       "61750   بعداز یه مدت درجه بندیش پاک میشه و قابل استفاد...  35.0   \n",
       "57936   یک روزه دستم رسید عالیه ممنونم از دیجی کالا وا...  60.0   \n",
       "146577  به عنوان هدیه گرفتم عالیه طرحش جنسش وقتی بسترو...  88.0   \n",
       "\n",
       "        verification_status  \n",
       "134230                    0  \n",
       "142564                    0  \n",
       "61750                     0  \n",
       "57936                     0  \n",
       "146577                    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(testing_data.count())\n",
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset majors\n",
    "* We shall know some major information about our datasets, So we use `df.count()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>rate</th>\n",
       "      <th>verification_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000</td>\n",
       "      <td>130000</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70257</td>\n",
       "      <td>125351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>عالیه</td>\n",
       "      <td>عالی</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2347</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90083.573031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.770243</td>\n",
       "      <td>0.170185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>51933.709169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.287678</td>\n",
       "      <td>0.375796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45131.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>90174.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>135159.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>179999.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id   title comment           rate  verification_status\n",
       "count   130000.000000  130000  130000  130000.000000        130000.000000\n",
       "unique            NaN   70257  125351            NaN                  NaN\n",
       "top               NaN   عالیه    عالی            NaN                  NaN\n",
       "freq              NaN    2347     229            NaN                  NaN\n",
       "mean     90083.573031     NaN     NaN      57.770243             0.170185\n",
       "std      51933.709169     NaN     NaN      34.287678             0.375796\n",
       "min          0.000000     NaN     NaN       0.000000             0.000000\n",
       "25%      45131.500000     NaN     NaN      36.000000             0.000000\n",
       "50%      90174.500000     NaN     NaN      60.000000             0.000000\n",
       "75%     135159.250000     NaN     NaN      87.000000             0.000000\n",
       "max     179999.000000     NaN     NaN     100.000000             1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>rate</th>\n",
       "      <th>verification_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27564.000000</td>\n",
       "      <td>27564</td>\n",
       "      <td>27564</td>\n",
       "      <td>27564.000000</td>\n",
       "      <td>27564.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17830</td>\n",
       "      <td>27017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>عالیه</td>\n",
       "      <td>عالی</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>516</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>89846.437491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.711685</td>\n",
       "      <td>0.170512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>52061.127631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.219519</td>\n",
       "      <td>0.376089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>44560.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>89717.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>134733.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>179997.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  title comment          rate  verification_status\n",
       "count    27564.000000  27564   27564  27564.000000         27564.000000\n",
       "unique            NaN  17830   27017           NaN                  NaN\n",
       "top               NaN  عالیه    عالی           NaN                  NaN\n",
       "freq              NaN    516      38           NaN                  NaN\n",
       "mean     89846.437491    NaN     NaN     57.711685             0.170512\n",
       "std      52061.127631    NaN     NaN     34.219519             0.376089\n",
       "min         11.000000    NaN     NaN      0.000000             0.000000\n",
       "25%      44560.750000    NaN     NaN     36.000000             0.000000\n",
       "50%      89717.000000    NaN     NaN     60.000000             0.000000\n",
       "75%     134733.500000    NaN     NaN     86.000000             0.000000\n",
       "max     179997.000000    NaN     NaN    100.000000             1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting training sentences and labels\n",
    "* We should extract sentences and labels from training and testing files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = training_data.comment.astype(str).to_numpy()\n",
    "training_labels = training_data.verification_status.astype(str).to_numpy()\n",
    "\n",
    "testing_sentences = testing_data.comment.astype(str).to_numpy()\n",
    "testing_labels = testing_data.verification_status.astype(str).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing data\n",
    "* for text preprossecing, Tensorflow offers us awesome methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 600\n",
    "trunc_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=oov_tok, num_words=vocab_size)\n",
    "normalizer = Normalizer()\n",
    "stemmer = Stemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "* As we have our tokenizer and normalizer, we start obtaining padded data by preprocessing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Note]: Training sentences saved successfully!\n",
      "[Note]: Testing sentences saved successfully!\n",
      "\n",
      "[Note]: Training sentences array shape: (130000,)\n",
      "[Note]: Testing sentences array shape: (27564,)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./model/training_sentences.npy'):\n",
    "    training_sentences = np.load('./model/training_sentences.npy', allow_pickle=True)\n",
    "    print(\"[Note]: Training sentences loaded successfully!\")\n",
    "else:\n",
    "    for idx, sentence in enumerate(training_sentences):\n",
    "        training_sentences[idx] = normalizer.normalize(sentence)\n",
    "    training_sentences = np.asarray(training_sentences)\n",
    "    np.save('./model/training_sentences.npy', training_sentences)\n",
    "    print(\"[Note]: Training sentences saved successfully!\")\n",
    "\n",
    "if os.path.exists('./model/testing_sentences.npy'):\n",
    "    testing_sentences = np.load('./model/testing_sentences.npy', allow_pickle=True)\n",
    "    print(\"[Note]: Testing sentences loaded successfully!\")\n",
    "else:\n",
    "    for idx, sentence in enumerate(testing_sentences):\n",
    "        testing_sentences[idx] = normalizer.normalize(sentence)\n",
    "    testing_sentences = np.asarray(testing_sentences)\n",
    "    np.save('./model/testing_sentences.npy', testing_sentences)\n",
    "    print(\"[Note]: Testing sentences saved successfully!\")\n",
    "    \n",
    "print()\n",
    "print(\"[Note]: Training sentences array shape:\", training_sentences.shape)\n",
    "print(\"[Note]: Testing sentences array shape:\", testing_sentences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word to vector\n",
    "* By using `Tokenizer.fit_on_texts()` we can tokenize all sentences\n",
    "and by `Tokenizer.texts_to_sequences()` we can create sequences used in paddind generation by `pad_sequences`.\n",
    "\n",
    "# Saving processed data\n",
    "* Because of the fact that processing and cleaning this much data takes a lot of time and effort, we save it for further usage by `np.save()`. If `padded.npy` exists in directory `model`, it will be loaded automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Note]: Train padded array saved in model directory.\n",
      "[Note]: Test padded array saved in model directory.\n",
      "\n",
      "Train padded array shape: (130000, 600)\n",
      "Test padded array shape: (27564, 600)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./model/train_padded.npy'):\n",
    "    train_padded = np.load('./model/train_padded.npy')\n",
    "    print(\"[Note]: Train padded loaded successfully!\")\n",
    "else:\n",
    "    tokenizer.fit_on_texts(training_sentences)\n",
    "    word_index = tokenizer.word_index\n",
    "    train_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "    train_padded = pad_sequences(train_sequences, truncating='post', maxlen=max_length)\n",
    "    np.save('./model/train_padded.npy', arr=train_padded)\n",
    "    print(\"[Note]: Train padded array saved in model directory.\")\n",
    "\n",
    "if os.path.exists('./model/test_padded.npy'):\n",
    "    test_padded = np.load('./model/test_padded.npy')\n",
    "    print(\"[Note]: Test padded loaded successfully!\")\n",
    "else:\n",
    "    tokenizer.fit_on_texts(testing_sentences)\n",
    "    word_index = tokenizer.word_index\n",
    "    test_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "    test_padded = pad_sequences(test_sequences, truncating='post', maxlen=max_length)\n",
    "    np.save('./model/test_padded.npy', arr=test_padded)\n",
    "    print(\"[Note]: Test padded array saved in model directory.\")\n",
    "\n",
    "print()\n",
    "print(\"Train padded array shape:\", train_padded.shape)\n",
    "print(\"Test padded array shape:\", test_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? نسبت به امکاناتش و کاراییش در مقایسه با سایر برندها به قیمتش نمی‌ارزه حتی کسایی که <OOV> فقط بخاطر عشق به این برند هستش نه کارایی و <OOV> بالاترش چون با یک تومن کمتر از این پول میشه یه برند دیگه با امکانات مشابه خرید\n",
      "--------------\n",
      "نسبت به امکاناتش و کاراییش در مقایسه با سایر برندها.. به قیمتش نمی‌ارزه.. حتی کسایی که میخرنش فقط بخاطر عشق به این برند هستش.. نه کارایی و امکانت بالاترش\n",
      "چون با یک تومن کمتر از این پول میشه یه برند دیگه با امکانات مشابه خرید\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(decode_review(test_padded[1000]))\n",
    "print(\"--------------\")\n",
    "print(testing_sentences[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "* Now we have our train and tets data, So shall we begin training. By as it comes first,\n",
    "at first we try neural network.\n",
    "* Creating our network with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/embedding_ops.py:132: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=4),\n",
    "    tf.keras.layers.GRU(32),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 600, 16)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 596, 64)           5184      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 149, 64)           0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 32)                9312      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 174,529\n",
      "Trainable params: 174,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CallBack Class\n",
    "* We use `tf.keras.callbacks` to be in touch with logs that contains accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc') > 0.99):\n",
    "            self.model.stop_training = True\n",
    "            print(\"[Note]: Reached training accuracy of 95%\")\n",
    "\n",
    "mycallback = Callback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing learning process with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "[Note]: Model loaded successfully!\n",
      "  2656/130000 [..............................] - ETA: 7:57 - loss: 1.8604 - acc: 0.7455- ETA: 8:17 - loss: 1"
     ]
    }
   ],
   "source": [
    "if os.path.exists('./model/model.h5'):\n",
    "    model = tf.keras.models.load_model('./model/model.h5')\n",
    "    print(\"[Note]: Model loaded successfully!\")\n",
    "else:\n",
    "    %tensorboard --logdir logs/scalars\n",
    "    num_epochs = 20\n",
    "    model.fit(train_padded, training_labels, epochs=num_epochs,\n",
    "              validation_data=(test_padded, testing_labels),\n",
    "              callbacks=[mycallback, tensorboard_callback])\n",
    "    try:\n",
    "        model.save('./model/model.h5', overwrite=True)\n",
    "    except:\n",
    "        pass\n",
    "    print(\"[Note]: Model saved successfully!\")\n",
    "    \n",
    "train_loss, train_acc = model.evaluate(train_padded, training_labels)\n",
    "test_loss, test_acc = model.evaluate(test_padded, testing_labels)\n",
    "\n",
    "print(\"Acuuracy over train set:\", train_acc)\n",
    "print(\"Accuracy over test set:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
